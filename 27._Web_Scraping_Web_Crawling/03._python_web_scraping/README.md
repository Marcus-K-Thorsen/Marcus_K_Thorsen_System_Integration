# How to setup

```bash
$ poetry init -n
$ poetry add beautifulsoup4 requests lxml
```

# How to run

```bash
$ poetry run python main.py
```

# What does this project do?

This project shows how to use Python to scrape data from a web page.  
It downloads a Wikipedia page, parses the HTML, and extracts lists of Monty Python projects grouped by category.  
The script demonstrates how to collect structured information from a real website using BeautifulSoup and requests.

# How is this web scraping different from the Node.js example in 01._node_web_scraping?

In the Node.js example in `01._node_web_scraping/index.js`, the script **fetches data from the internet** (for example, from a website), processes it, and then **creates a new local HTML file** (`index.html`) with the scraped data. This means you start with no `index.html` file, and the script generates it for you using the data it collects online.

In contrast, the Python example in `03._python_web_scraping/main.py` downloads a web page from the internet (Wikipedia), parses the HTML, and extracts structured information, but it does **not** create a new HTML fileâ€”it just prints or processes the data in Python.

**Summary:**  
- **Node.js example:** Fetches data from the internet and creates a new local HTML file with the results.
- **Python example:** Fetches data from the internet and processes it in Python, but does not create a new HTML file.